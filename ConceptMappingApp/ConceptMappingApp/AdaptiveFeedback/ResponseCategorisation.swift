//
//  ResponseCategorisation.swift
//  ConceptMappingApp
//
//  Created by Jennifer on 07/02/2023.
//

import Foundation

enum ResponseCategorisationValues {
    case InComplete // part of answer and accurate
    case InAccurate // complete, but not accurate
    case InAccurateSuperfluous // complete, with extra elements
    case InCompleteInAccurate // part of answer,  not accurate
    case CompleteAccurate // complete, accurate
    case NotApplicable // can't infer safe conclusion
}

struct ResponseCategorisation {
    // define what category the answer is
    // part of the answer -- several keywords are present
    // complete answer -- all keywords are present
    // accurate answer -- all keywords are correct context
    // not accurate -- incorrect concept, incorrect relationship
    var word_count = 0
    var common_word_count : [Int] = []
    var changedConcept: Int
    
    var exp_concepts = [ExpertConcept(id: 0, concept: "A linked list is an implementation of a dictionary", image: "Linkedlist", example: "My dictionary can be created using a linked list as the underlying data structure.", alternativeExample: "A dictionary can be created using a linked list", keywords:  "linked list implementation", relationships: [[0,2]], linkedRelations: "A dictionary stores information and can perform operations.", difficulty: 0, learningOutcome: "define an implementation of a dictionary"), ExpertConcept(id: 1, concept: "Hashing based structures can be used to implement it", image: "hashingStructure", example: "If you wanted to use a dictionary, you could use a hash table.", alternativeExample: "A dictionary can be created using a hashing-based structure", keywords:  "hashing structures", relationships: [[1, 2], [1, 7], [1, 9], [1, 12]], linkedRelations: "Such structures can have different ways to determine behaviour and performance can vary.", difficulty: 0, learningOutcome: "define an implementation of a dictionary"), ExpertConcept(id: 2, concept: "A dictionary stores a set of items, with 3 basic operations", image: "dictionary", example: "If you have a dictionary, you have a choice of 3 operations to perform on the contents.", alternativeExample: "Dictionaries have 3 operations for a set of items", keywords: "3 dictionary stores set items operations", relationships: [[2, 44], [0, 2], [2, 6], [1, 2 ], [2, 45]], linkedRelations: "They can be implemented using different data structures to perform the operations.", difficulty: 0, learningOutcome: "define a dictionary"), ExpertConcept(id: 3, concept: "Insert adds an item x to the set of not already present", image: "insertion", example: "If I Insert(3) into the set [2,6,78], it could be inserted: [2,6,78,3]. I couldn't Insert 2 because it's already in the set.", alternativeExample: "Insertion will add a new item to a set", keywords:  "insert adds item set not current present", relationships: [[3, 6], [3, 46]], linkedRelations: "This is one of the three dictionary operations.", difficulty: 0, learningOutcome: "define an operation of a dictionary"), ExpertConcept(id: 4, concept: "Delete removes x if present in the set", image: "deletion", example: "I could Delete(2) from [4,2,6,76]. The result is [4,6,76].", alternativeExample: "Deletion removes an item stored in a set", keywords:  "delete removes present current set", relationships: [[4, 6]], linkedRelations: "This is one of the three operations for a dictionary.", difficulty: 0, learningOutcome: "define an operation of a dictionary"), ExpertConcept(id: 5, concept: "Lookup returns true if x is in the set, else returns false", image: "lookup", example: "If I Lookup(2) in the set [4,54,3,2], it would return True.", alternativeExample: "Lookup determines if an item is in a set", keywords:  "lookup returns true set current", relationships: [[5, 6]], linkedRelations: "This is one of the three operations for a dictionary.", difficulty: 0, learningOutcome: "define an operation of a dictionary"), ExpertConcept(id: 6, concept: "The 3 operations are: Lookup, Insert and Delete", image: "operations", example: "I can Lookup, Insert and Delete on my dictionary", alternativeExample: "Lookup, Insert and Delete are built-in operations", keywords:  "operations lookup insert delete ", relationships: [[2, 6], [3, 6], [4, 6], [5, 6]], linkedRelations: "Each operation will take a set amount of time, depending on how many items are at a single location.", difficulty: 0, learningOutcome: "define the 3 operations of a dictionary"), ExpertConcept(id: 7, concept: "They are called probabilistic data structures", image: "probabilistic", example: "An element of probability is involved when using a hashing-based dictionary.", alternativeExample: "Hashing-based structures are probabilistic data structures", keywords:  "dictionaries probabilistic data structure", relationships: [[1, 7], [7, 8], [7, 9]], linkedRelations: "The performance of these data structures will be determined with a probability, such as 'This performance holds with a high probability.'.", difficulty: 0, learningOutcome: "define the type of the data structures mentioned"), ExpertConcept(id: 8, concept: "The worst/ average case is linear time for each operation", image: "timing", example: "Lookup, Insert and Delete can be performed in linear time in the average/ worst use case.", alternativeExample: "The average time case is linear for every operation", keywords:  "worst average case linear time ", relationships: [[7, 8], [8, 9]], linkedRelations: "This performance holds with a high probability, but can be different due to the nature of probabilistic data structures.", difficulty: 1, learningOutcome: "define the worst/ average time case"), ExpertConcept(id: 9, concept: "Performance holds with high probability in the expected case", image: "performance", example: "On average, the performance of my dictionary will be the same and this is guaranteed for a certain probability.", alternativeExample: "Usually, there is a high probability that the performance will stay around this", keywords:  "performance high probability expected", relationships: [[7, 9], [8, 9], [1, 9], [9, 39], [9, 10], [9, 11], [9, 47]], linkedRelations: "Hashing-based structures have a high probability of the expected case happening and a low probability of the worst case happening.", difficulty: 1, learningOutcome: "define the performance in the expected case"), ExpertConcept(id: 10, concept: "Expected case is the average over all random choices", image: "average", example: "To find the expected case on a set, I need to find the average of all the choices in the set.", alternativeExample: "The mean performance for all random choices is the expected case", keywords: "expected average choices random", relationships: [[9, 10]], linkedRelations: "This is most likely to happen, apart from in very unlikely events.", difficulty: 1, learningOutcome: "define expected case"), ExpertConcept(id: 11, concept: "The worst case can be very bad, but often unlikely to happen", image: "badPerf", example: "There is a small chance my dictionary will not be able to perform an operation as it takes too long.",  alternativeExample: "Performance can be very bad in the worst case, but this is unlikely to happen", keywords: "worst case bad unlikely happen", relationships: [[9, 11]], linkedRelations: "This is because they are probabilistic data structures, so you can't always depend on the best case happening.", difficulty: 1, learningOutcome: "define the worst case"), ExpertConcept(id: 12, concept: "Behaviour is determined by 1 or 2 hash functions", image: "hashFunctions", example: "If my data structure uses 1 has function, the resulting value will be the position the item is stored in. If my data structure uses 2, there are two possible locations for the item.", alternativeExample: "Hashing-based data structures use 1 or 2 hashing functions", keywords:  "1 2 hash functions", relationships: [[12, 38], [1, 12], [12, 37], [12, 48], [12, 49], [12, 50], [12, 51]], linkedRelations: "These functions determine the location of an item and there are different techniques depending on how many hash functions are used.", difficulty: 1, learningOutcome: "define the behaviour of hashing-based structures"), ExpertConcept(id: 13, concept: "There is a fixed upper bound of n on num. items in the set", image: "upperBound", example: "If n = 4, there can only be 4 items in the set", alternativeExample: "The amount of items is bounded by a value n", keywords:  "fixed upper bound items number set ", relationships: [[13, 14], [13, 38], [13, 39], [13, 52]], linkedRelations: "This determines the longest execution time for an operation and limits the space storage.", difficulty: 2, learningOutcome: "define the limits of the size of a set"), ExpertConcept(id: 14, concept: "Space usage is bounded in terms of n. o(n)", image: "space", example: "If n = 100, the storage used for my dictionary will not exceed 100.", alternativeExample: "The space in a set is O(n)", keywords:  "space usage bounded O(n) ", relationships: [[14, 39], [13, 14], [14, 38]], linkedRelations: "This will affect the space performance, in terms of how many locations an item can be stored in and will increase/ decrease the size of the set of return values.", difficulty: 2, learningOutcome: "define the limits of the space storage of a set"), ExpertConcept(id: 15, concept: "Function values are probabilistically independent", image: "independent", example: "The probability that the dictionary return item x will not affect the probability of the dictionary returning y.", alternativeExample: "The probability of a value being returned is independent to the probability of another value being picked", keywords:  "function values probabilistically independent ", relationships: [[15, 16]], linkedRelations: "This means a single function return value will not impact another value.", difficulty: 2, learningOutcome: "define the probability behaviour of function values"), ExpertConcept(id: 16, concept: "A function return is equal to a set value with probability 1/r", image: "1r", example: "The probability that x is returned is 1/r. The probability that y is returned is also 1/r.", alternativeExample: "A value in the set has probability 1/r of being picked as a function return", keywords:  "function return equal probability 1/r ", relationships: [[16, 38], [15, 16], [16, 43], [16, 53]], linkedRelations: "This value is determined in constant time and the probability of a single item being returned decreases as the number of items in the return set increases.", difficulty: 2, learningOutcome: "define the probability behaviour of function values"), ExpertConcept(id: 17, concept: "Rehashing is expensive but it is unlikely to happen.", image: "expensive", example: "It will take a lot of time to re-insert all the items into the set, but has a low probability of happening.", alternativeExample: "Rehashing takes a lot of computational time, but has little likelihood of occurring.", keywords: "rehashing expensive unlikely.", relationships: [[17, 19], [17, 18], [17, 54], [17, 20]], linkedRelations: "For rehashing to occur, two new random hash functions have to be found and then all the times re-inserted.", difficulty: 0, learningOutcome: "Define the risk of rehashing."), ExpertConcept(id: 18, concept: "Rehashing is when 2 new hash functions are used instead.", image: "rehashing", example: "If h1(x) and h2(x) result in a cycle, two new random hash functions h3(x) and h4(x) can be found so there is no longer a cycle.", alternativeExample: "Two new random hash functions are found for rehashing.", keywords: "rehashing 2 new hash functions", relationships: [[17, 18], [18, 55]], linkedRelations: "All items are re-inserted, taking O(1) time per insertion.", difficulty: 0, learningOutcome: "Define rehashing"), ExpertConcept(id: 19, concept: "If rehashing is O(n), the expected time for all rehashes is O(n).", image: "on", example: "To rehash 10 items, it will take O(10). To rehash the items twice, it will also take O(10).", alternativeExample: "The expected time for all rehashes is O(n), given one rehash takes O(n).", keywords: "rehashing o(n) expected o(n)", relationships: [[17, 19], [19, 22], [19, 23]], linkedRelations: "The likelihood of multiple rehashes taking place is very low.", difficulty: 1, learningOutcome: "Define rehashing execution time"), ExpertConcept(id: 20, concept: "The expected number of rehashes during n insertions is 1.", image: "o1", example: "During the insertion of 15 elements, rehashing will likely only be needed once.", alternativeExample: "When inserting n elements, only 1 rehash is expected to be needed.", keywords: "expected rehashes insertions 1", relationships: [[17, 20], [20, 21]], linkedRelations: "Rehashing takes O(n), so O(n) time will be needed on top of the O(1) for any additional insertions.", difficulty: 2, learningOutcome: "Define the expected number of rehashes."), ExpertConcept(id: 21, concept: "The probability of x rehashes decreases as x increases.", image: "negcorr", example: "When c = 3, the probability of one rehash is 1/2. The probability of two rehashes is 1/4.", alternativeExample: "The likelihood of rehashes taking place reduces as the number of rehashes increases.", keywords: "probability rehashes decreases increases", relationships: [[20, 21]], linkedRelations: "Only 1 rehash is expected during n insertions and the likelihood of more happening decreases with the number of total rehashes.", difficulty: 2, learningOutcome: "Define the probability pattern of rehash occurrences."), ExpertConcept(id: 22, concept: "The amortised cost of rehashing is constant.", image: "o1", example: "If i rehash a set of 10 items or 35 items, both will take only constant time.", alternativeExample: "Rehashing takes constant times in terms of the cost per item.", keywords: "amortised cost rehashing constant", relationships: [[19, 22], [22, 48], [22, 23]], linkedRelations: "Rehashing takes O(n) time, so it is constant time for each item.", difficulty: 1, learningOutcome: "Define the cost of rehashing"), ExpertConcept(id: 23, concept: "The amortised expected time for rehashes over n insertions is O(1) per insertion.", image: "o1", example: "For 15 insertions, it only takes O(1) time to insert 1 item.", alternativeExample: "The expected time per item for insertion is O(1) over n insertions.", keywords: "amortised time o(1) per insertion.", relationships: [[22, 23], [19, 23]], linkedRelations: "Amortised expected time for insertion is O(1). The same as the time for Lookup and Deletion.", difficulty: 1, learningOutcome: "Define the amortised expected time per item"), ExpertConcept(id: 24, concept: "Insertion will loop n times if there is a cycle.", image: "loop", example: "If there is a cycle when i am inserting an element into a set of 7 items, insertion will happen 7 times before rehashing has to happen.", alternativeExample: "If there is a cycle in a cuckoo graph, insertion will happen until the same element is inserted twice and then rehashing will occur.", keywords: "insertion loop times cycle", relationships: [[24, 48], [24, 25]], linkedRelations: "Cycles are detected during insertions and is the only time rehashing will take place.", difficulty: 0, learningOutcome: "Define what happens during a cycle in cuckoo hashing."), ExpertConcept(id: 25, concept: "If there isn't a cycle, an insertion can be completed.", image: "cuckooGraph", example: "I can insert an item into the dictionary if there is no cycle as no items will have to be relocated.", alternativeExample: "A cycle stops an insertion being completed successfully as it will infinitely loop.", keywords: "isn't cycle insertion completed", relationships: [[25, 52], [24, 25]], linkedRelations: "Insertions are dependent on cycles as cycles will result in infinite insertion loops.", difficulty: 0, learningOutcome: "Define the conditions for a successful insertion."), ExpertConcept(id: 26, concept: "Inserting a key into a cycle always causes a rehash.", image: "cyclicGraph", example: "If i create a cycle by adding an item to a set, there will always be an item that needs to be moved to a new location. This will happen infinitely, so rehashing is needed.", alternativeExample: "A rehash is needed if an item is inserted into a cycle.", keywords: "inserting cycle rehash", relationships: [[26, 55]], linkedRelations: "Insertions are dependent on cycles as cycles will result in infinite insertion loops.", difficulty: 1, learningOutcome: "Define the conditions for rehashing"), ExpertConcept(id: 27, concept: "There is a low probability of 2 nodes being connected.", image: "lowProb", example: "The more nodes there are, for a small number of edges, the less likely it to that two nodes will be connected.", alternativeExample: "Given the right conditions, there is always a low chance of two nodes being directly connected.", keywords: "low probability nodes connected", relationships: [[27, 77], [27, 28], [27, 29]], linkedRelations: "Induction can prove the relationship between two nodes in a large table, with a small number of edges.", difficulty: 1, learningOutcome: "Define the relationship between two nodes being connected"), ExpertConcept(id: 28, concept: "Only for a large enough num. of nodes compared to edges.", image: "smallGraph", example: "This is less likely to occur if there were 4 nodes and 3 edges, compared to 10 nodes and 3 edges.", alternativeExample: "This only happens where there is a significant difference in the number of nodes compared to edges.", keywords: "large enough nodes compared edges", relationships: [[27, 28], [28, 29]], linkedRelations: "Induction can prove the relationship between two nodes in a large table, with a small number of edges.", difficulty: 1, learningOutcome: "Define the relationship between two nodes being connected"), ExpertConcept(id: 29, concept: "Table size (r) >= 2*c*keys (n) where c > 1", image: "formula", example: "This is less likely to occur if there were 4 nodes and 3 edges, compared to 10 nodes and 3 edges.", alternativeExample: "r >= 2*c*keys where c is a constant, c > 1.", keywords: "table size >= 2*c*keys c > 1", relationships: [[27, 29], [28, 29], [29, 30]], linkedRelations: "Induction can prove the relationship between two nodes in a large table, with a small number of edges.", difficulty: 1, learningOutcome: "Define the relationship between two nodes being connected"), ExpertConcept(id: 30, concept: "This can be proved by induction.", image: "induction", example: "There are three main parts to induction, with an integer example, with an algebraic formula and explaining the formula.", alternativeExample: "Proof by induction can show the chance of two nodes being connected.", keywords: "induction", relationships: [[29, 30]], linkedRelations: "For a dictionary with a large number of nodes and a small number of edges, the chance of two nodes being connected is small.", difficulty: 0, learningOutcome: "Define how the node connection relationship can be proved"), ExpertConcept(id: 31, concept: "Cuckoo hashing is not suitable for certain applications.", image: "notSuitable", example: "Database indexing cannot use cuckoo hashing because the chances of failure are too high.", alternativeExample: "Some applications cannot use cuckoo hashing.", keywords: "not suitable applications", relationships: [[31, 48], [31, 32]], linkedRelations: "Cuckoo hashing can lead to high failure rates, leading to the failure of an application in certain contexts.", difficulty: 0, learningOutcome: "Explain cuckoo hashing in the context of real-life applications."), ExpertConcept(id: 32, concept: "A failure probability can lead to a failure rate that is too high.", image: "failure", example: "If a system fails, it is no longer useful to the customer or provider which can lead to many losses.", alternativeExample: "A failure rate will increase as the failure probability increases.", keywords: "failure probability rate high lead high failure", relationships: [[31, 32], [32, 34]], linkedRelations: "Cuckoo hashing can lead to high failure rates, leading to the failure of an application in certain contexts.", difficulty: 0, learningOutcome: "Explain the impact of a high failure probability."), ExpertConcept(id: 33, concept: "High performance routing and database indexing would not be suitable in this scenario.", image: "indexing", example: "High-performance routing means a lot of information needs to be executed at any time and a failure would stop this.", alternativeExample: "When using cuckoo hashing, database indexing and high-performance routing cannot be used.", keywords: "High performance routing database indexing", relationships: [[31, 33], [32, 33]], linkedRelations: "Cuckoo hashing can limit the performance of systems because of the failure probability.", difficulty: 1, learningOutcome: "Define applications that can't use cuckoo hashing"), ExpertConcept(id: 34, concept: "New techniques can help reduce high failure rates.", image: "techniques", example: "An example includes using a stash (piece of memory) and move elements can't be inserted into the stash.", alternativeExample: "To reduce failure rates, certain features can be implemented.", keywords: "techniques reduce high rates", relationships: [[32, 34], [34, 35]], linkedRelations: "Techniques can maintain performance whilst changing failure probability.", difficulty: 1, learningOutcome: "Explain how to improve high failure rates."), ExpertConcept(id: 35, concept: "Performance is preserved and failure probability decreased.", image: "decreaseFailure", example: "An example includes using a stash (piece of memory) and move elements can't be inserted into the stash.", alternativeExample: "Features can decrease the probability of failure and preserve performance.", keywords: "performance preserved  decreased", relationships: [[34, 35]], linkedRelations: "Techniques can maintain performance whilst changing failure probability.", difficulty: 0, learningOutcome: "Explain how to improve high failure rates."), ExpertConcept(id: 36, concept: "Must assume insertions first check if element in list", image: "assume", example: "When I add item x to the dictionary, I first look through the dictionary to see if x is already there.", alternativeExample: "Before inserting an element into a list, first check if it is already inserted.", keywords: "insertions check element list", relationships: [[3, 36]], linkedRelations: "The expected time of an insertion is O(1), given a check is first carried out to see if the item is already there.", difficulty: 2, learningOutcome: "Define the assumptions for insertions"), ExpertConcept(id: 37, concept: "Take an item and return random values from a set.", image: "hashFunctions", example: "When I pass an item through h1(x), one of the items from the set is returned. It could be any of them and will be random.", alternativeExample: "An item is passed through a hash function and an item from the set is returned randomly.", keywords: "item return random set take values", relationships: [[12, 37], [37, 41], [37, 38], [16, 37], [37, 51], [37, 42], [37, 56]], linkedRelations: "There is a set of return values guaranteed from a hash function.", difficulty: 1, learningOutcome: "Define what hashing is"), ExpertConcept(id: 38, concept: "The set of return values is {1, …., r}.", image: "returnHash", example: "When I pass an item through h1(x), the possible values returned are from the set {1, ..., r}.", alternativeExample: "The values in a set, from 1 to r, are the return values of a hash function.", keywords: "return values", relationships: [[16, 38], [12, 38], [37, 38], [38, 57], [38, 14], [14, 38]], linkedRelations: "There is a set of return values guaranteed from a hash function.", difficulty: 1, learningOutcome: "Define the set of return values."), ExpertConcept(id: 39, concept: "Space performance has modest constant-factor overhead.", image: "o1", example: "If there are n items, the space usage is O(n).", alternativeExample: "Space performance is not too large to impact overall performance.", keywords: "space performance constant factor overhead", relationships: [[9, 39], [39, 58], [14, 39], [39, 41]], linkedRelations: "Space performance is bound by logarithms and has an overhead.", difficulty: 1, learningOutcome: "Define the space performance of hashing"), ExpertConcept(id: 40, concept: "Performance is usually logarithmic time bounds.", image: "logGraph", example: "When inserting into a balanced search tree, it will take logarithmic time.", alternativeExample: "Balanced search trees use logarithmic time bounds.", keywords: "time logarithmic bounds", relationships: [[40, 44]], linkedRelations: "Space performance has an overhead, bound by logarithmic bounds.", difficulty: 1, learningOutcome: "Define the space performance bounds"), ExpertConcept(id: 41, concept: "Items stored are the same size", image: "equal", example: "Item a and item b in the set are the same size.", alternativeExample: "All items in the set are equal size.", keywords: "items stored same size", relationships: [[37, 41], [39, 41], [14, 41]], linkedRelations: "Items stored are the same size and can be compared in constant time.", difficulty: 1, learningOutcome: "Define the size of items in the set"), ExpertConcept(id: 42, concept: "Compare any 2 items in constant time", image: "o1", example: "Item a and item b can be compared in constant time, with no other overhead.", alternativeExample: "Two items from a set can be compared in constant time.", keywords: "compare 2 items constant time", relationships: [[37, 42]], linkedRelations: "Items stored are the same size and can be compared in constant time.", difficulty: 1, learningOutcome: "Define comparison time between items in a set"), ExpertConcept(id: 43, concept: "Function values are computed in constant time.", image: "o1", example: "If I pass item a into hash function h1(x), it will take constant time to find the return value.", alternativeExample: "Hash functions compute the return value in constant time.", keywords: "function values computed constant time", relationships: [[16, 43]], linkedRelations: "Hash functions compute a return value, where the item is stored, in constant time.", difficulty: 1, learningOutcome: "Define the time taken to compute function values"), ExpertConcept(id: 44, concept: "A balanced search tree is an implementation", image: "bst", example: "If I wanted to use a dictionary, I could use a balanced search tree.", alternativeExample: "To use a dictionary, a balanced search tree can be used.", keywords: "balanced search tree", relationships: [[2, 44], [40, 44]], linkedRelations: "Dictionaries can be implemented in different ways, using different techniques.", difficulty: 0, learningOutcome: "Define an implementation of a dictionary"), ExpertConcept(id: 45, concept: "An operation where x is already stored is only constant-factor time extra.", image: "o1", example: "If I try to insert an element already in the set, it will only take constant-time (looking through the set to check if it is there).", alternativeExample: "It takes constant time to perform an operation when the item is already stored.", keywords: "operation stored constant factor time", relationships: [[2, 45], [45, 52]], linkedRelations: "The time of an operation depends on several factors.", difficulty: 1, learningOutcome: "Define what happens when an item is already stored"), ExpertConcept(id: 46, concept: "The probability of x hashing to y’s bucket is O(1/r)", image: "sameHash", example: "If y hashes to the bucket that contains x, this event has probability of O(1/r) of happening.", alternativeExample: "The probability of an item being hashed to a bucket already containing an item is O(1/r).", keywords: "probability hashing bucket o(1/r)", relationships: [[3, 46], [46, 59], [46, 60]], linkedRelations: "Insertion can lead to collisions.", difficulty: 1, learningOutcome: "Define the probability of two items hashing to the same bucket"), ExpertConcept(id: 47, concept: "Sometimes required to guarantee the worst-case constant lookup", image: "worst", example: "If I have a high  chance of failure, I will want to know what happens in the worst case.", alternativeExample: "The worst-case can have a different times than the expected case.", keywords: "guarantee worst case lookup", relationships: [[9, 47], [47, 58], [47, 61], [47, 62]], linkedRelations: "Sometimes the expected case is not good enough and the worst case much be calculated.", difficulty: 1, learningOutcome: "Define what happens not in the expected case"), ExpertConcept(id: 48, concept: "Cuckoo hashing uses 2 hash functions", image: "twoHash", example: "If the location for item x is full for the first hash function, the second one if used to find another location.", alternativeExample: "Two hash functions are used for cuckoo hashing.", keywords: "cuckoo hashing 2 hash functions", relationships: [[12, 48], [24, 48], [48, 63], [48, 64], [48, 65], [48, 66], [48, 67], [22, 48], [31, 48]], linkedRelations: "Cuckoo hashing has specific operation implementations.", difficulty: 0, learningOutcome: "Define how many hash functions are used in cuckoo hashing"), ExpertConcept(id: 49, concept: "Only one hash function is used.", image: "oneHash", example: "One hash function is used to find the storage location of an item.", alternativeExample: "Hashing with chaining only uses one hash function.", keywords: "one hash function", relationships: [[12, 49], [49, 73]], linkedRelations: "Different dictionary implementations use different numbers of hash functions.", difficulty: 0, learningOutcome: "Define how many hash functions are used for hashing with chaining"), ExpertConcept(id: 50, concept: "Hash functions used for a dictionary must have these properties.", image: "twoHash", example: "For a dictionary to be accurately implemented the data structure must have specific properties, such as only 1 or 2 hash functions.", alternativeExample: "Hash functions must have certain properties.", keywords: "hash functions properties.", relationships: [[12, 50], [50, 61]], linkedRelations: "Behaviour and time are dependent on the properties of a hash function.", difficulty: 1, learningOutcome: "Define the properties for dictionary implementations"), ExpertConcept(id: 51, concept: "Hashing-based dictionaries decide where to store an item", image: "returnHash", example: "A hash function h(x) will return a value corresponding to the position in a dictionary", alternativeExample: "Dictionaries determine where an item is stored, by using hashing.", keywords: "Hashing based dictionaries store item", relationships: [[12, 51], [37, 51]], linkedRelations: "Hashing-based dictionaries using a number of hash functions to determine the location of an item.", difficulty: 0, learningOutcome: "Define a hashing based dictionary"), ExpertConcept(id: 52, concept: "Time for an item operation is: constant * num. items in the bucket", image: "chaining", example: "To lookup an item in a bucket with 2 items, it takes a constant * 2.", alternativeExample: "The time it takes to perform an operation on an item depends on the number of items in the corresponding bucket multiplied by a constant.", keywords: "time item operation constant * items bucket", relationships: [[13, 52], [45, 52], [25, 52], [52, 68]], linkedRelations: "Buckets are where items are stored and operations can be performed on them.", difficulty: 2, learningOutcome: "Define the time taken to perform an operation"), ExpertConcept(id: 53, concept: "The hash function will return a fixed value for the same input.", image: "oneHash", example: "For a hash function h(x), if i pass in a, the answer will always be the same.", alternativeExample: "The same value is returned from a hash function when the same input is used.", keywords: "hash function return value same input", relationships: [[16, 53]], linkedRelations: "The function return values have equal probability of being returned.", difficulty: 0, learningOutcome: "Define what a hash function returns"), ExpertConcept(id: 54, concept: "If it takes too long, start again with two new hash functions", image: "rehashing", example: "If there is a cyclic graph, the process goes on forever so it is better to restart", alternativeExample: "Two new hash functions are used if the insertion takes too long and the process is restarted.", keywords: "too long start again new hash functions", relationships: [[17, 54], [54, 55], [54, 69]], linkedRelations: "Cuckoo hashing can result in cyclic graphs and repetitive processes.", difficulty: 1, learningOutcome: "Define what happens when a cyclic graph is found"), ExpertConcept(id: 55, concept: "Cyclic graphs require rehashing to take place.", image: "cyclicGraph", example: "If I try to insert an item and there is a cycle, rehashing will take place.", alternativeExample: "Rehashing must take place when there is a cyclic graph.", keywords: "cyclic graphs rehashing", relationships: [[18, 55], [54, 55], [55, 77], [26, 55]], linkedRelations: "Cuckoo hashing can result in cyclic graphs and restart the hashing process.", difficulty: 1, learningOutcome: "Define what happens when there is a cyclic graph"), ExpertConcept(id: 56, concept: "It is likely there will be collision between items.", image: "collision", example: "Two items, when passed through the same hash function, may produce the same value, resulting in a collision.", alternativeExample: "Two items may collide in a dictionary.", keywords: "collision items", relationships: [[37, 56], [56, 57], [56, 59], [56, 62], [56, 70]], linkedRelations: "Items can collide and there are solutions to fix this.", difficulty: 0, learningOutcome: "Explain that items can collide"), ExpertConcept(id: 57, concept: "There are a set of values with the same hash value h1", image: "sameHashVal", example: "For a hash function h(x), h(a) = h(b) = same value", alternativeExample: "The is a set of items that return the same hash value when passed through the same hash function.", keywords: "set values same hash value", relationships: [[38, 57], [56, 57]], linkedRelations: "If two items return the same hash value, there will be collisions.", difficulty: 0, learningOutcome: "Define what a collision is"), ExpertConcept(id: 58, concept: "Could make a huge table, but very space inefficient", image: "largeTable", example: "The larger the table, the more space is required.", alternativeExample: "It is space inefficient to use a large table.", keywords: "table space inefficient", relationships: [[39, 58], [47, 58], [58, 71]], linkedRelations: "A larger tables results in a reduced chance of collisions, but require more space performance.", difficulty: 1, learningOutcome: "Define when to use a larger table"), ExpertConcept(id: 59, concept: "h1(x) = h1(y) end up in the same position", image: "collision", example: "h(x) = 5, h(y) = 5 so they end up in the same position.", alternativeExample: "Two items can end up in the same position from the same hash function.", keywords: "h1(x) h1(y) same position", relationships: [[46, 59], [56, 59]], linkedRelations: "Collisions can occur.", difficulty: 1, learningOutcome: "Define what a collision means"), ExpertConcept(id: 60, concept: "Average expected cost on an item is O(1/r)", image: "1r", example: "The expected time to be spent on an item is O(1/r).", alternativeExample: "The average expected time of an item in O(1/r).", keywords: "average cost o(1/r)", relationships: [[46, 60], [60, 61]], linkedRelations: "Collisions increase the time taken to perform an operation.", difficulty: 1, learningOutcome: "Define the expected time cost"), ExpertConcept(id: 61, concept: "Total expected time is sum of expected time for all elements", image: "linearity", example: "If the expected time for item a = 10 and item b = 4, the total expected time is 14.", alternativeExample: "The total expected time for all elements in the sum of each expected time.", keywords: "total time sum all elements", relationships: [[60, 61], [47, 61], [50, 61]], linkedRelations: "The expected time can only be used sometimes, sometimes the worst case must be calculated.", difficulty: 1, learningOutcome: "Define the total expected time"), ExpertConcept(id: 62, concept: "Can find hash functions with no collisions", image: "perfect", example: "A hash function can pass any value in and won't return the same value for any.", alternativeExample: "Certain hash functions have no collisions.", keywords: "hash functions no collisions", relationships: [[47, 62], [56, 62], [62, 72]], linkedRelations: "Perfect hash functions mean there are no collisions between items.", difficulty: 0, learningOutcome: "Explain that hash functions can have no collisions"), ExpertConcept(id: 63, concept: "Structure may be more complicated than chaining", image: "structure", example: "Chaining uses lists, but cuckoo hashing has one list and multiple hash functions.", alternativeExample: "Cuckoo hashing is a more complicated structure than chaining.", keywords: "structure complicated", relationships: [[48, 63], [63, 73]], linkedRelations: "Hashing with chaining and cuckoo hashing use different data structures", difficulty: 1, learningOutcome: "Explain there is a difference between chaining and cuckoo hashing"), ExpertConcept(id: 64, concept: "Lookups and deletions are O(1)", image: "o1", example: "When looking for an item in a dictionary, it takes O(1) time.", alternativeExample: "It takes O(1) time for lookups and deletions.", keywords: "lookups deletions o(1)", relationships: [[48, 64]], linkedRelations: "Cuckoo hashing has fast operations, with possible cycles.", difficulty: 0, learningOutcome: "Define operation times for cuckoo hashing"), ExpertConcept(id: 65, concept: "An item can be stored in two positions: h1(x) or h2(x)", image: "twoHash", example: "h1(x) will give a different value to h2(x) for any item x.", alternativeExample: "Two positions are valid for an item in cuckoo hashing.", keywords: "item two positions", relationships: [[48, 65], [65, 66], [65, 74]], linkedRelations: "Looking up an item requires you to check both hash functions sometimes.", difficulty: 0, learningOutcome: "Explain how the two hashing functions work for cuckoo hashing"), ExpertConcept(id: 66, concept: "Lookup an item by looking at two positions in the array", image: "twoHash", example: "If item x is not at position h1(x), then h2(X) is checked and it is found there.", alternativeExample: "The two values from the hash functions are checked when looking up an item.", keywords: "lookup item two positions", relationships: [[48, 66], [65, 66]], linkedRelations: "Cuckoo hashing uses two hash functions.", difficulty: 1, learningOutcome: "Define how to lookup an item"), ExpertConcept(id: 67, concept: "No secondary structure is used, 1 element, 1 position", image: "perfect", example: "No chaining is used, one element is joined with one bucket.", alternativeExample: "Only one data structure is used in cuckoo hashing.", keywords: "no secondary structure", relationships: [[48, 67]], linkedRelations: "Cuckoo hashing uses two hash functions.", difficulty: 1, learningOutcome: "Explain the data structure in cuckoo hashing"), ExpertConcept(id: 68, concept: "The data structure (bucket) can be a simple linked list.", image: "chaining", example: "A linked list can represent a single hash function value.", alternativeExample: "A linked list can be used to implement chaining with hashing", keywords: "bucket linked list", relationships: [[52, 68], [68, 70]], linkedRelations: "Chaining with hashing uses lists of lists.", difficulty: 0, learningOutcome: "Define an implementation of hashing with chaining"), ExpertConcept(id: 69, concept: "Repeat until all items are stored or taken too long", image: "repeat", example: "If there is no cycle, the process will carry on until all items in the set have a stored position with no other item.", alternativeExample: "Insertion repeats until it has taken too long or all the items have been stored.", keywords: "repeat until items too long", relationships: [[54, 69], [69, 75]], linkedRelations: "Cuckoo hashing can result in rehashing.", difficulty: 0, learningOutcome: "Define the conditions for insertion in cuckoo hashing"), ExpertConcept(id: 70, concept: "Solve collisions by having a pointer from h1 to a data structure", image: "chaining", example: "If two items have the same hash function value, store them in a list connected to the value position.", alternativeExample: "A link from each bucket to an external data structure can be used to solve collisions.", keywords: "collisions pointer data structure", relationships: [[56, 70], [68, 70], [70, 73]], linkedRelations: "Items can collide when using hashing for a dictionary.", difficulty: 2, learningOutcome: "Explain how to solve collisions for hashing with chaining"), ExpertConcept(id: 71, concept: "Increasing n decreases probability collisions", image: "negcorr", example: "If there are 5 buckets and 2 items, there is a low chance of collisions. If there are 5 buckets and 6 items, there is a higher probability (certain) of collisions.", alternativeExample: "More collisions are likely to occur when there are more items.", keywords: "increasing n decreases probability collisions", relationships: [[58, 71]], linkedRelations: "Items can collide in hashing structures.", difficulty: 2, learningOutcome: "Define the probability of collisions in relation to hashing."), ExpertConcept(id: 72, concept: "Perfect hash functions allow to insert directly to an array", image: "perfect", example: "There are no collisions, so only one array is needed and each item will have a unique position in the array.", alternativeExample: "Perfect hash functions mean there are no collisions, so items can be inserted directly into an array.", keywords: "perfect hash functions insert directly items array", relationships: [[62, 72]], linkedRelations: "Perfect hash functions stop the issue of collisions.", difficulty: 2, learningOutcome: "Define the reason for perfect hash functions in the context of dictionaries"), ExpertConcept(id: 73, concept: "This is called hashing with chaining.", image: "chaining", example: "Using a list of lists to store items at the same location is hashing with chaining.", alternativeExample: "This technique is hashing with chaining.", keywords: "hashing chaining", relationships: [[49, 73], [63, 73], [70, 73]], linkedRelations: "Hashing with chaining can use complicated structures.", difficulty: 0, learningOutcome: "Define hashing with chaining"), ExpertConcept(id: 74, concept: "There may be no space for a new item. Both positions filled.", image: "repeat", example: "If the values for h1(x) and h2(x) are storing other items, both positions are already filled.", alternativeExample: "Both values of the hash functions may be filled with other items.", keywords: "no space new item", relationships: [[65, 74], [74, 75], [74, 76]], linkedRelations: "If there is no space for a new item, a cuckoo must be thrown.", difficulty: 1, learningOutcome: "Define a issue with insertions in cuckoo hashing."), ExpertConcept(id: 75, concept: "Remove item y at h1(x) and replace with new item.", image: "cuckooThrow", example: "if item a is already in the bucket, it is removed and item b is placed there. Item a is then moved to its other position found from the second hash function.", alternativeExample: "The current item is removed and the new item is stored there.", keywords: "remove item replace", relationships: [[69, 75], [74, 75], [75, 76]], linkedRelations: "Insertions in cuckoo hashing can result in items being moved around.", difficulty: 1, learningOutcome: "Explain how to throw a cuckoo"), ExpertConcept(id: 76, concept: "Throw a cuckoo", image: "cuckooThrow", example: "When an item needs to be stored and both its hash function values are already stored, you throw a cuckoo.", alternativeExample: "Throwing a cuckoo", keywords: "throw cuckoo", relationships: [[74, 76], [75, 76], [76, 77]], linkedRelations: "In cuckoo hashing, sometimes you have to throw a cuckoo.", difficulty: 1, learningOutcome: "Use the term 'Throw a cuckoo'"), ExpertConcept(id: 77, concept: "A cuckoo graph can show the process of this.", image: "repeat", example: "A cuckoo graph shows the relocation of items during insertion, after a cuckoo has been thrown.", alternativeExample: "When you throw a cuckoo, a graph can show the process.", keywords: "cuckoo graph", relationships: [[55, 77], [76, 77], [27, 77]], linkedRelations: "A cuckoo graph shows the process of throwing a cuckoo.", difficulty: 1, learningOutcome: "Explain what a cuckoo graph shows")]
   
    var keywords = ["linked list implementation", "hashing structures", "3 dictionary set stores items operations", "insert adds item current set not present", "delete removes present current set", "lookup returns true current set", "operations lookup insert delete", "probabilistic data structures dictionaries", "worst average case linear time", "performance high probability expected", "expected average random choices", "worst case bad unlikely happen", "1 2 hash functions", "fixed upper bound items number set", "space usage bounded o(n)", "function values probabilistically independent", "function return equal probability 1/r", "rehashing expensive unlikely", "rehashing 2 new hash functions", "rehashing o(n) expected o(n)", "expected rehashes insertions 1", "probability rehashes decreases increases", "amortised cost rehashing constant", "amortised time o(1) per insertion", "insertion times loop cycle", "isn't cycle insertion completed", "inserting cycle rehash", "low probability nodes connected", "large enough nodes compared edges", "table size >= 2*c*keys c > 1", "induction", "not suitable applications", "failure probability rate high lead high failure", "High performance routing database indexing", "techniques reduce high rates", "performance preserved decreased", "insertions check element list", "item return random set take values", "return values", "space performance constant factor overhead", "logarithmic time bounds", "items stored same size", "comparing constant time", "function values computed constant time", "balanced search tree", "operation stored constant factor time", "probability hashing bucket o(1/r)", "guarantee worst case lookup", "cuckoo hashing 2 hash functions", "one hash function", "Hash functions properties", "Hashing based dictionaries store item", "time item operation constant * items bucket", "hash function return value same input", "too long start again new hash functions", "cyclic graphs rehashing", "collision items", "set values same hash value", "table space inefficient", "h1(x) h1(y) same position", "average cost o(1/r)", "total time sum expected all elements", "hash functions no collisions", "structure complicated", "lookups deletions o(1)", "item two positions", "lookup item two positions", "secondary structure no", "bucket linked list", "repeat until items too long", "collisions pointer data structure", "increasing n decreases probability collisions", "perfect hash functions insert directly items array", "hashing chaining", "no space new item", "remove item replace", "throw cuckoo", "cuckoo graph"]
    
    var key_concepts = ["A linked list is an implementation of a dictionary", "Hashing based structures can be used to implement it", "A dictionary stores a set of items, with 3 basic operations", "Insert adds an item x to the set of not already present", "Delete removed x if present in the set", "Lookup returns true if x is in the set, else returns false", "The 3 operations are: Lookup, Insert and Delete", "They are called probabilistic data structures", "The worst/ average case is linear time for each operation", "Performance holds with high probability in the expected case", "Expected case is the average over all random choices", "The worst case can be very bad, but often unlikely to happen", "Behaviour is determined by 1 or 2 hash functions", "There is a fixed upper bound of n on num. items in the set", "Space usage is bounded in terms of n. O(n)", "Function values are probabilistically independent", "A function return is equal to a set value with probability 1/r", "Rehashing is expensive but it is unlikely to happen.", "Rehashing is when 2 new hash functions are used instead.", "If rehashing is O(n), the expected time for all rehashes is O(n).", "The expected number of rehashes during n insertions is 1.", "The probability of x rehashes decreases as x increases.", "The amortised cost of rehashing is constant.", "The amortised expected time for rehashes over n insertions is O(1) per insertion.", "Insertion will loop n times if there is a cycle.", "If there isn't a cycle, an insertion can be completed.", "Inserting a key into a cycle always causes a rehash.", "There is a low probability of 2 nodes being connected.", "Only for a large enough num. of nodes compared to edges.", "Table size (r) >= 2*c*keys (n) where c > 1", "This can be proved by induction.", "Cuckoo hashing is not suitable for certain applications.", "A failure probability can lead to a failure rate that is too high.", "High-performance routing and database indexing would not be suitable in this scenario.", "New techniques can help reduce high failure rates.", "Performance is preserved and failure probability decreased.", "Must assume insertions first check if element in list", "Take an item and return random values from a set.", "The set of return values is {1, …., r}.", "Space performance has modest constant-factor overhead.", "Performance is usually logarithmic time bounds.", "Items stored are the same size", "Comparing items takes constant time", "Function values are computed in constant time.", "A balanced search tree is an implementation", "An operation where x is already stored is only constant-factor time extra.", "The probability of x hashing to y’s bucket is O(1/r)", "Sometimes required to guarantee the worst-case constant lookup", "Cuckoo hashing uses 2 hash functions", "Only one hash function is used.", "Hash functions used for a dictionary must have these properties.", "Hashing-based dictionaries decide where to store an item", "Time for an item operation is: constant * num. items in the bucket", "The hash function will return a fixed value for the same input.", "If it takes too long, start again with two new hash functions", "Cyclic graphs require rehashing to take place.", "It is likely there will be collision between items.", "There are a set of values with the same hash value h1", "Could make a huge table, but very space inefficient", "h1(x) = h1(y) end up in the same position", "Average expected cost on an item is O(1/r)", "Total expected time is sum of expected time for all elements", "Can find hash functions with no collisions", "Structure may be more complicated than chaining", "Lookups and deletions are O(1)", "An item can be stored in two positions: h1(x) or h2(x)", "Lookup an item by looking at two positions in the array", "No secondary structure is used, 1 element, 1 position", "The data structure (bucket) can be a simple linked list.", "Repeat until all items are stored or taken too long", "Solve collisions by having a pointer from h1 to a data structure", "Increasing n decreases probability collisions", "Perfect hash functions allow for insertions directly to array", "This is called hashing with chaining.", "There may be no space for a new item. Both positions filled.", "Remove item y at h1(x) and replace with new item.", "Throw a cuckoo", "A cuckoo graph can show the process of this."]

    
    
    mutating func findCorrespondingConcept(user_concept: Node) -> ([String], [String], Int, Int, String, [ExpertConcept]) {
        let wordsToRemove = ["a", "all", "at", "the", "can", "allow", "allows", "array", "and", "it", "a", "about", "above", "after", "again", "against", "all", "am", "an", "and", "any", "are", "aren't", "as", "be", "because", "been", "before", "being", "below", "between", "both", "but", "by", "can't", "cannot", "could", "couldn't", "did", "didn't", "do", "does", "doesn't", "doing", "don't", "down", "during", "each", "few", "for", "from", "further", "had", "hadn't", "has", "hasn't", "have", "haven't", "having", "here", "here's", "how", "how's", "i", "i'd", "i'll", "i'm", "i've", "if", "in", "into", "is", "isn't", "it", "it's", "its", "itself", "let's", "more", "most", "mustn't", "of", "off", "on", "once", "only", "or", "other", "ought", "out", "over", "own", "shan't", "should", "shouldn't", "so", "some", "such", "than", "that", "that's", "the", "their", "theirs", "them", "themselves", "then", "there", "there's", "these", "they", "they'd", "they'll", "they're", "they've", "this", "those", "through", "to", "too", "r", "under", "until", "up", "uses", "very", "was", "wasn't", "we", "we'd", "we'll", "we're", "we've", "were", "weren't", "what", "what's", "when", "when's", "where", "where's", "which", "while", "who", "who's", "whom", "why", "why's", "with", "won't", "would", "require", "wouldn't", "you", "you'd", "you'll", "you're", "you've", "your", "yours", "yourself", "yourselves", "*", "num.", "",  "x", "terms"]
        
        print("User conceptL ", user_concept)
        
        let lowercase = user_concept.title.lowercased()
        if lowercase == "" {
            return ([], [], -1, -1, "", [])
        }
        let lowercase_words = lowercase // .withoutPunctuations
        let lowercase_word = lowercase_words.components(separatedBy: " ")
        
        var words: [String] = []
        for i in 0..<lowercase_word.count {
            words.append(String(lowercase_word[lowercase_word.index(lowercase_word.startIndex, offsetBy: i)]))
        }
        
        let sentence = words.filter({ wordsToRemove.contains($0) == false })

        for keyword in keywords {
            self.word_count =  0
            for word in sentence {
                if keyword.lowercased().contains(word) {
                    self.word_count += 1
                }
            }
            common_word_count.append(word_count)
        }
        
        let max_index = common_word_count.max()
        if max_index == nil {
            // do nothing
            return ([], [], -1, -1, "", [])
        } else {
            let common_concept_index = common_word_count.firstIndex(of: max_index!)
            let common_concept = key_concepts[common_concept_index!].lowercased()
            print(common_concept)
            let concept_keywords_array = keywords[common_concept_index!].lowercased().components(separatedBy: " ")
            
            print()
            print(sentence.count, max_index!)
            
            return (sentence, concept_keywords_array, sentence.count, concept_keywords_array.count, common_concept, exp_concepts)
        }
    }
    
    func determineCategory(user_concept: [String], expert_concept: [String], user_count: Int, expert_count: Int) -> ResponseCategorisationValues {
        print("expert concept", expert_concept)
        print("User concept: ", user_concept)

        let complete = checkComplete(user_concept: user_count, expert_concept: expert_count)
        let accuracy = checkAccuracy(user_sentence: user_concept, expert_keywords: expert_concept)
        
        if complete == 0 && accuracy == 1 {
            print("Incomplete")
            return .InComplete
        } else if (complete == 1 && accuracy == 0) || (complete == -1 && accuracy == 0){
            print("Inaccurate")
            return .InAccurate
        } else if complete == -1 && accuracy == 1 {
            print("InaccurateSuperfluous")
            return .InAccurateSuperfluous
        } else if complete == 0 && accuracy == 0 {
            print("InCompleteInAccurate")
            return .InCompleteInAccurate
        } else if complete == 1 && accuracy == 1 {
            print("CompleteAccurate")
            return .CompleteAccurate
        }
        
        print("Not applicable")
        return .NotApplicable
    }
    
    func checkAccuracy(user_sentence: [String], expert_keywords: [String]) -> Int {
        // if contains keywords from other concepts, not in current set -- inaccurate
        let all_keywords = keywords.joined(separator:" ").lowercased()
        let keywords_array = all_keywords.components(separatedBy: " ")
        var difference_count = 0
        
        for keyword in keywords_array {
            for word in user_sentence {
                if !expert_keywords.contains(word) {
                    if keyword.contains(word) {
                        difference_count += 1
                    }
                }
            }
        }
        if difference_count > 0 {
            return 0
        }
        return 1
    }
    
    func checkComplete(user_concept: Int, expert_concept: Int) -> Int {
        if user_concept == expert_concept {
            return 1
        } else if user_concept > expert_concept {
            return -1
        } else {
            return 0
        }
    }
    
    func determineKnowledgeLevel (user_count: Int, expert_count: Int) -> Int {
        let average = round(Double(expert_count / 2))
        let average_level = Int(average)
        
        if user_count < average_level {
            return -1
        } else if user_count == average_level {
            return 0
        } else {
            return 1
        }
    }
}

/*
"A linked list is an implementation of a dictionary", ---
"Hashing based structures can be used to implement it" ---
"A dictionary stores a set of items, with 3 basic operations", --- 2
"Insert adds an item x to the set of not already present" --- insertion
"Delete removed x if present in the set", --- deletion 4
"Lookup returns true if x is in the set, else returns false", ---
"The 3 operations are: Lookup, Insert and Delete", --- operations
"They are called probabilistic data structures", -- probabilistic
"The worst/ average case is linear time for each operation",--- timimng
 
"Performance holds with high probability in the expected case", ---
"Expected case is the average over all random choices", ---
"The worst case can be very bad, but often unlikely to happen",
"Behaviour is determined by 1 or 2 hash functions",
"There is a fixed upper bound of n on num. items in the set",
"Space usage is bounded in terms of n. O(n)",
"Function values are probabilistically independent",
"A function return is equal to a set value with probability 1/r",
"Rehashing is expensive but it is unlikely to happen.",
"Rehashing is when 2 new hash functions are used instead.",
"If rehashing is O(n), the expected time for all rehashes is O(n).",
"The expected number of rehashes during n insertions is 1.",
"The probability of x rehashes decreases as x increases.",
"The amortised cost of rehashing is constant.",
"The amortised expected time for rehashes over n insertions is O(1) per insertion.",
"Insertion will loop n times if there is a cycle.",
"If there isn't a cycle, an insertion can be completed.",
"Inserting a key into a cycle always causes a rehash.",
"There is a low probability of 2 nodes being connected.",
"Only for a large enough num. of nodes compared to edges.",
"Table size (r) >= 2*c*keys (n) where c > 1",
"This can be proved by induction.",
"Cuckoo hashing is not suitable for certain applications.",
"A failure probability can lead to a failure rate that is too high.",
"High-performance routing and database indexing would not be suitable in this scenario.",
"New techniques can help reduce high failure rates.",
"Performance is preserved and failure probability decreased.",
"Must assume insertions first check if element in list",
"Take an item and return random values from a set.",
"The set of return values is {1, …., r}.",
"Space performance has modest constant-factor overhead.",
"Performance is usually logarithmic time bounds.",
"Items stored are the same size",
"Comparing items takes constant time",
"Function values are computed in constant time.",
"A balanced search tree is an implementation",
"An operation where x is already stored is only constant-factor time extra.",
"The probability of x hashing to y’s bucket is O(1/r)",
"Sometimes required to guarantee the worst-case constant lookup",
"Cuckoo hashing uses 2 hash functions",
"Only one hash function is used.",
"Hash functions used for a dictionary must have these properties.",
"Hashing-based dictionaries decide where to store an item",
"Time for an item operation is: constant * num. items in the bucket",
"The hash function will return a fixed value for the same input.",
"If it takes too long, start again with two new hash functions",
"Cyclic graphs require rehashing to take place.",
"It is likely there will be collision between items.",
"There are a set of values with the same hash value h1",
"Could make a huge table, but very space inefficient",
"h1(x) = h1(y) end up in the same position",
"Average expected cost on an item is O(1/r)",
"Total expected time is sum of expected time for all elements",
"Can find hash functions with no collisions",
"Structure may be more complicated than chaining",
"Lookups and deletions are O(1)", <<<<<<<<<<<<,<
"An item can be stored in two positions: h1(x) or h2(x)",
"Lookup an item by looking at two positions in the array",
"No secondary structure is used, 1 element, 1 position",
"The data structure (bucket) can be a simple linked list.",
"Repeat until all items are stored or taken too long",
"Solve collisions by having a pointer from h1 to a data structure",
"Increasing n decreases probability collisions",
"Perfect hash functions allow for insertions directly to array",
"This is called hashing with chaining.",
"There may be no space for a new item. Both positions filled.",
"Remove item y at h1(x) and replace with new item.",
"Throw a cuckoo",
"A cuckoo graph can show the process of this.",
*/

// ["linked list implementation", "hashing structures", "dictionary set stores items operations", "insert adds item current set not present", "delete removes present current set", "lookup returns true current set", "operations lookup insert delete", "probabilistic data structures dictionaries", "worst average case linear time", "performance high probability expected", "expected average random choices", "worst case bad unlikely", "1 2 hash functions", "fixed upper bound items number set", "space usage bounded o(n)", "function values probabilistically independent", "function return equal probability 1/r", "rehashing expensive unlikely", "rehashing 2 new hash functions", "rehashing o(n) expected o(n)", "expected rehashes insertions 1", "probability rehashes decreases increases", "amortised cost rehashing constant", "amortised time o(1) per insertion", "insertion times loop cycle", "isn't cycle insertion completed", "inserting cycle rehash", "low probability nodes connected", "large enough nodes compared edges", "table size >= 2*c*keys c > 1", "induction", "not suitable applications", "failure probability rate high lead high failure", "High performance routing database indexing", "techniques reduce high rates", "performance preserved decreased", "insertions check element list", "item return random set", "return values", "space performance constant factor overhead", "logarithmic time bounds", "items stored same size", "comparing constant time", "function values computed constant time", "balanced search tree", "operation stored constant factor time", "probability hashing bucket o(1/r)", "guarantee worst case lookup", "cuckoo hashing 2 hash functions", "one hash function", "Hash functions properties", "Hashing based dictionaries store item", "time item operation constant * items bucket", "hash function return value same input", "too long start again new hash functions", "cyclic graphs rehashing", "collision items", "set values same hash value", "table space inefficient", "h1(x) h1(y) same position", "average cost o(1/r)", "total time sum expected all elements", "hash functions no collisions", "structure complicated", "lookups deletions o(1)", "item two positions", "lookup item two positions", "secondary structure no", "bucket linked list", "repeat until items too long", "collisions pointer data structure", "increasing n decreases probability collisions", "perfect hash functions insert directly", "hashing chaining", "no space new item", "remove item replace", "throw cuckoo", "cuckoo graph"]
